{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717b8bfc-fa80-4df5-993c-ffb767763899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File extracted successfully!\n",
      "ðŸ“‚ Loading file: extracted_data\\credit_score.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9724\\3996993916.py:41: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data Loaded Successfully!\n",
      "Initial Shape: (100000, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9724\\3996993916.py:65: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9724\\3996993916.py:66: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data Cleaned. Shape: (91518, 22)\n",
      "âœ… Encoding Completed. Feature Shape: (42732, 83506)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.32 GiB for an array with shape (83491, 42732) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vif_data\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Handle infinities and NaNs before VIF\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m X_vif \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], np\u001b[38;5;241m.\u001b[39mnan)\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Calculate VIF and keep only features with VIF < 5\u001b[39;00m\n\u001b[0;32m    117\u001b[0m vif_df \u001b[38;5;241m=\u001b[39m calculate_vif(X_vif)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:8099\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   8094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_replace) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[0;32m   8095\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   8096\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplacement lists must match in length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8097\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_replace)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8098\u001b[0m         )\n\u001b[1;32m-> 8099\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreplace_list(\n\u001b[0;32m   8100\u001b[0m         src_list\u001b[38;5;241m=\u001b[39mto_replace,\n\u001b[0;32m   8101\u001b[0m         dest_list\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[0;32m   8102\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   8103\u001b[0m         regex\u001b[38;5;241m=\u001b[39mregex,\n\u001b[0;32m   8104\u001b[0m     )\n\u001b[0;32m   8106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_replace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   8108\u001b[0m         is_re_compilable(regex)\n\u001b[0;32m   8109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_list_like(regex)\n\u001b[0;32m   8110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_dict_like(regex)\n\u001b[0;32m   8111\u001b[0m     ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:287\u001b[0m, in \u001b[0;36mDataManager.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    276\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    278\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_with_block(\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace_list\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    280\u001b[0m     src_list\u001b[38;5;241m=\u001b[39msrc_list,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m     already_warned\u001b[38;5;241m=\u001b[39m_AlreadyWarned(),\n\u001b[0;32m    286\u001b[0m )\n\u001b[1;32m--> 287\u001b[0m bm\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2270\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2271\u001b[0m     )\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2301\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2298\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2300\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2301\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2302\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2304\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.32 GiB for an array with shape (83491, 42732) and data type bool"
     ]
    }
   ],
   "source": [
    "# 01 Importing the Libraries\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ============================================================\n",
    "# 02 Extracting and Loading the Data\n",
    "# ============================================================\n",
    "\n",
    "zip_file = \"Credit_Score.zip\"\n",
    "\n",
    "# Extract the ZIP file\n",
    "if os.path.exists(zip_file):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"extracted_data\")\n",
    "    print(\"âœ… File extracted successfully!\")\n",
    "else:\n",
    "    print(\"âŒ Error: 'Credit_Score.zip' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Find the CSV file inside the extracted folder\n",
    "csv_files = [f for f in os.listdir(\"extracted_data\") if f.endswith(\".csv\")]\n",
    "\n",
    "if len(csv_files) == 0:\n",
    "    print(\"âŒ No CSV file found inside the ZIP.\")\n",
    "    exit()\n",
    "else:\n",
    "    csv_path = os.path.join(\"extracted_data\", csv_files[0])\n",
    "    print(f\"ðŸ“‚ Loading file: {csv_path}\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"âœ… Data Loaded Successfully!\")\n",
    "print(\"Initial Shape:\", df.shape)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\"ID\", \"Customer_ID\", \"Name\", \"SSN\", \"Type_of_Loan\", \"Credit_History_Age\"]\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "# ============================================================\n",
    "# 03 Data Cleaning\n",
    "# ============================================================\n",
    "\n",
    "cols_to_clean_and_convert = [\n",
    "    'Age', 'Annual_Income', 'Num_of_Loan', 'Num_of_Delayed_Payment',\n",
    "    'Changed_Credit_Limit', 'Outstanding_Debt', 'Amount_Invested_monthly',\n",
    "    'Monthly_Balance'\n",
    "]\n",
    "\n",
    "for col in cols_to_clean_and_convert:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.replace(r'[^\\d\\.\\-]', '', regex=True)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Fill missing values using forward + backward fill\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Remove outliers in Age\n",
    "if 'Age' in df.columns:\n",
    "    df = df[(df['Age'] >= 18) & (df['Age'] <= 100)]\n",
    "\n",
    "print(\"âœ… Data Cleaned. Shape:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 04 One Hot Encoding\n",
    "# ============================================================\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if 'Credit_Score' in categorical_cols:\n",
    "    categorical_cols.remove('Credit_Score')\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Encode target variable 'Credit_Score'\n",
    "credit_score_mapping = {\n",
    "    'Poor': 0,\n",
    "    'Fair': 1,\n",
    "    'Good': 2,\n",
    "    'Excellent': 3\n",
    "}\n",
    "\n",
    "df_encoded['Credit_Score_Encoded'] = df_encoded['Credit_Score'].map(credit_score_mapping)\n",
    "df_encoded.dropna(subset=['Credit_Score_Encoded'], inplace=True)\n",
    "\n",
    "y = df_encoded['Credit_Score_Encoded'].astype(int)\n",
    "X = df_encoded.drop(columns=['Credit_Score', 'Credit_Score_Encoded'])\n",
    "\n",
    "print(\"âœ… Encoding Completed. Feature Shape:\", X.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 05 Feature Selection using VIF\n",
    "# ============================================================\n",
    "\n",
    "def calculate_vif(df_vif):\n",
    "    \"\"\"Calculate Variance Inflation Factor (VIF)\"\"\"\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df_vif.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_vif.values, i) for i in range(df_vif.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Handle infinities and NaNs before VIF\n",
    "X_vif = X.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "\n",
    "# Calculate VIF and keep only features with VIF < 5\n",
    "vif_df = calculate_vif(X_vif)\n",
    "selected_features = vif_df[vif_df['VIF'] < 5]['feature'].tolist()\n",
    "X = X[selected_features]\n",
    "\n",
    "print(\"âœ… VIF Feature Selection Done. Remaining Features:\", len(selected_features))\n",
    "\n",
    "# ============================================================\n",
    "# 06 Logistic Regression Model\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model_lr = LogisticRegression(\n",
    "    multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42\n",
    ")\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr) * 100\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "cr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\n===============================\")\n",
    "print(\"ðŸ“Š Logistic Regression Results\")\n",
    "print(\"===============================\")\n",
    "print(f\"âœ… Accuracy: {accuracy_lr:.2f}%\")\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", cr)\n",
    "\n",
    "# ============================================================\n",
    "# 07 Visualization (Optional)\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d2963-d4ed-4912-a59d-47c8563b79a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
